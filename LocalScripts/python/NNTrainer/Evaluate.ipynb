{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f2ed03-312a-4620-8fa0-c202e7a10db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c002cddf-4e13-46f2-9e05-8982470583b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global parameters:\n",
    "indir = '../../input_trees/'\n",
    "jobname = 'tree_2LSSinclusive_baseline_Sept17'\n",
    "#jobname = 'tree_2016postVFPUL_2LSSmm_Sept23'\n",
    "\n",
    "modeldict = {\n",
    "    'QCD-VLLD_mu-classifier':'nnscore_qcd_vlldmu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8383b634-efb9-4b22-8656-f6dd07b4b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded.\n"
     ]
    }
   ],
   "source": [
    "#Given a TFile, read its branches into a dataframe.\n",
    "def read_file_into_df(filepath, truth=None):\n",
    "\n",
    "    filename = filepath.split('/')[-1]\n",
    "    sample = filename.split(\"_\")[1]\n",
    "    subsample = \"_\".join(filename.split(\"_\")[2:])\n",
    "    \n",
    "    #Exceptions\n",
    "    if 'QCD_' in filename or 'VLL' in filename:\n",
    "        sample = filename.split(\"_\")[1]+\"_\"+filename.split(\"_\")[2]\n",
    "        subsample = filename.split(\"_\")[3].split(\".\")[0]\n",
    "        \n",
    "    if subsample.endswith(\".root\"): subsample = subsample[:-5]\n",
    "\n",
    "    tfile = uproot.open(filepath)\n",
    "    \n",
    "    ttree = tfile['myEvents']\n",
    "    branches = ttree.keys()\n",
    "    awkarray = ttree.arrays(branches)\n",
    "    df = pd.DataFrame(awkarray.to_list())\n",
    "    if truth: df['truth'] = truth\n",
    "    df['sample'] = sample\n",
    "    df['subsample'] = subsample\n",
    "\n",
    "    return df\n",
    "\n",
    "def ApplyMinMax(X, min_filename, max_filename):\n",
    "    # Load min values from the file\n",
    "    minval = np.loadtxt(min_filename)\n",
    "    \n",
    "    # Load max values from the file\n",
    "    maxval = np.loadtxt(max_filename)\n",
    "    \n",
    "    #print('Min from txt: ', minval)\n",
    "    #print('Max from txt: ', maxval)\n",
    "    \n",
    "    # Calculate the difference\n",
    "    diff = maxval - minval\n",
    "    normed_X = X.copy()    \n",
    "    # Scale the data only for non-constant columns\n",
    "    nonconst = np.where(diff != 0)[0]\n",
    "    normed_X[:, nonconst] = 2 * ((X[:, nonconst] - minval[nonconst]) / diff[nonconst]) - 1.0\n",
    "    \n",
    "    return normed_X\n",
    "\n",
    "def write_df_into_file(df, filepath):\n",
    "\n",
    "    if df.empty:\n",
    "        with uproot.recreate(filepath) as file:\n",
    "            file['myEvents'] = {}\n",
    "\n",
    "    else:\n",
    "        df_drop = df.drop(columns=['sample', 'subsample'])        \n",
    "        data_dict = df_drop.to_dict('list')\n",
    "        with uproot.recreate(filepath) as file:\n",
    "            file['myEvents'] = data_dict\n",
    "\n",
    "print('Functions loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a468dd-61c7-4876-a6d3-a096d4ef8f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: tree_DYJetsToLL_M10to50.root\n",
      "Loading file: tree_DYJetsToLL_M50.root\n",
      "Loading file: tree_EGamma_EGamma_A.root\n",
      "Loading file: tree_EGamma_EGamma_B.root\n",
      "Loading file: tree_EGamma_EGamma_C.root\n",
      "Loading file: tree_EGamma_EGamma_D.root\n",
      "Loading file: tree_Higgs_bbH_HToZZTo4L.root\n",
      "Loading file: tree_Higgs_GluGluHToZZTo4L.root\n",
      "Loading file: tree_Higgs_GluGluToZH_HToZZTo4L.root\n",
      "Loading file: tree_Higgs_GluGluZH_HToWW_ZTo2L.root\n",
      "Loading file: tree_Higgs_ttHToNonbb.root\n",
      "Loading file: tree_Higgs_VBF_HToZZTo4L.root\n",
      "Loading file: tree_Higgs_VHToNonbb.root\n",
      "Loading file: tree_HTbinnedWJets_100to200.root\n",
      "Loading file: tree_HTbinnedWJets_1200to2500.root\n",
      "Loading file: tree_HTbinnedWJets_200to400.root\n",
      "Loading file: tree_HTbinnedWJets_2500toInf.root\n",
      "Loading file: tree_HTbinnedWJets_400to600.root\n",
      "Loading file: tree_HTbinnedWJets_600to800.root\n",
      "Loading file: tree_HTbinnedWJets_70to100.root\n",
      "Loading file: tree_HTbinnedWJets_800to1200.root\n",
      "Loading file: tree_QCD_EMEnriched_120to170.root\n",
      "Loading file: tree_QCD_EMEnriched_15to20.root\n",
      "\u001b[0;31mWarning: Empty file written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_QCD_EMEnriched_15to20.root\u001b[0m\n",
      "\n",
      "Loading file: tree_QCD_EMEnriched_170to300.root\n",
      "Loading file: tree_QCD_EMEnriched_20to30.root\n",
      "\u001b[0;31mWarning: Empty file written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_QCD_EMEnriched_20to30.root\u001b[0m\n",
      "\n",
      "Loading file: tree_QCD_EMEnriched_300toInf.root\n",
      "Loading file: tree_QCD_EMEnriched_30to50.root\n",
      "\u001b[0;31mWarning: Empty file written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_QCD_EMEnriched_30to50.root\u001b[0m\n",
      "\n",
      "Loading file: tree_QCD_EMEnriched_50to80.root\n",
      "Loading file: tree_QCD_EMEnriched_80to120.root\n",
      "Loading file: tree_QCD_MuEnriched_120to170.root\n",
      "Loading file: tree_QCD_MuEnriched_170to300.root\n",
      "Loading file: tree_QCD_MuEnriched_20to30.root\n",
      "Loading file: tree_QCD_MuEnriched_300to470.root\n",
      "Loading file: tree_QCD_MuEnriched_30to50.root\n",
      "Loading file: tree_QCD_MuEnriched_470to600.root\n",
      "Loading file: tree_QCD_MuEnriched_50to80.root\n",
      "Loading file: tree_QCD_MuEnriched_600to800.root\n",
      "Loading file: tree_QCD_MuEnriched_800to1000.root\n",
      "Loading file: tree_QCD_MuEnriched_80to120.root\n",
      "Loading file: tree_Rare_THQ.root\n",
      "Loading file: tree_Rare_THW.root\n",
      "Loading file: tree_Rare_TTHH.root\n",
      "Loading file: tree_Rare_TTTJ.root\n",
      "Loading file: tree_Rare_TTTT.root\n",
      "Loading file: tree_Rare_TTTW.root\n",
      "Loading file: tree_Rare_TTWH.root\n",
      "Loading file: tree_Rare_TTWW.root\n",
      "Loading file: tree_Rare_TTWZ.root\n",
      "Loading file: tree_Rare_TTZH.root\n",
      "Loading file: tree_Rare_TTZZ.root\n",
      "Loading file: tree_Rare_tZq_ll.root\n",
      "Loading file: tree_SingleMuon_SingleMuon_A.root\n",
      "Loading file: tree_SingleMuon_SingleMuon_B.root\n",
      "Loading file: tree_SingleMuon_SingleMuon_C.root\n",
      "Loading file: tree_SingleMuon_SingleMuon_D.root\n",
      "Loading file: tree_SingleTop_s-channel_LeptonDecays.root\n",
      "Loading file: tree_SingleTop_t-channel_AntiTop_InclusiveDecays.root\n",
      "Loading file: tree_SingleTop_t-channel_Top_InclusiveDecays.root\n",
      "Loading file: tree_SingleTop_tW_AntiTop_InclusiceDecays.root\n",
      "Loading file: tree_SingleTop_tW_Top_InclusiveDecays.root\n",
      "Loading file: tree_TTBar_TTTo2L2Nu.root\n",
      "Loading file: tree_TTBar_TTToSemiLeptonic.root\n",
      "Loading file: tree_TTW_TTWToLNu.root\n",
      "Loading file: tree_TTZ_TTZToLL.root\n",
      "Loading file: tree_VLLD_ele_M100.root\n",
      "Loading file: tree_VLLD_ele_M1000.root\n",
      "Loading file: tree_VLLD_ele_M200.root\n",
      "Loading file: tree_VLLD_ele_M300.root\n",
      "Loading file: tree_VLLD_ele_M400.root\n",
      "Loading file: tree_VLLD_ele_M600.root\n",
      "Loading file: tree_VLLD_ele_M800.root\n",
      "Loading file: tree_VLLD_mu_M100.root\n",
      "Loading file: tree_VLLD_mu_M200.root\n",
      "Loading file: tree_VLLD_mu_M300.root\n",
      "Loading file: tree_VLLD_mu_M400.root\n",
      "Loading file: tree_VLLD_mu_M600.root\n",
      "Loading file: tree_VLLD_mu_M800.root\n",
      "Loading file: tree_VLLS_ele_M100.root\n",
      "Loading file: tree_VLLS_ele_M1000.root\n",
      "Loading file: tree_VLLS_ele_M125.root\n",
      "Loading file: tree_VLLS_ele_M150.root\n",
      "Loading file: tree_VLLS_ele_M200.root\n",
      "Loading file: tree_VLLS_ele_M250.root\n",
      "Loading file: tree_VLLS_ele_M300.root\n",
      "Loading file: tree_VLLS_ele_M350.root\n",
      "Loading file: tree_VLLS_ele_M400.root\n",
      "Loading file: tree_VLLS_ele_M450.root\n",
      "Loading file: tree_VLLS_ele_M500.root\n",
      "Loading file: tree_VLLS_ele_M750.root\n",
      "Loading file: tree_VLLS_mu_M100.root\n",
      "Loading file: tree_VLLS_mu_M1000.root\n",
      "Loading file: tree_VLLS_mu_M125.root\n",
      "Loading file: tree_VLLS_mu_M150.root\n",
      "Loading file: tree_VLLS_mu_M200.root\n",
      "Loading file: tree_VLLS_mu_M250.root\n",
      "Loading file: tree_VLLS_mu_M300.root\n",
      "Loading file: tree_VLLS_mu_M400.root\n",
      "Loading file: tree_VLLS_mu_M450.root\n",
      "Loading file: tree_VLLS_mu_M500.root\n",
      "Loading file: tree_VLLS_mu_M750.root\n",
      "Loading file: tree_VLLS_tau_M100.root\n",
      "Loading file: tree_VLLS_tau_M125.root\n",
      "Loading file: tree_VLLS_tau_M150.root\n",
      "Loading file: tree_VLLS_tau_M200.root\n",
      "Loading file: tree_VLLS_tau_M250.root\n",
      "Loading file: tree_VLLS_tau_M300.root\n",
      "Loading file: tree_VLLS_tau_M350.root\n",
      "Loading file: tree_VLLS_tau_M400.root\n",
      "Loading file: tree_WGamma_Inclusive.root\n",
      "Loading file: tree_WGamma_WGToLNuG_01J.root\n",
      "Loading file: tree_WpWp_WpWpJJEWK.root\n",
      "Loading file: tree_WpWp_WpWpJJQCD.root\n",
      "Loading file: tree_WWW_Inclusive.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "128/128 [==============================] - 1s 4ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WWW_Inclusive.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WWZ_Inclusive.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "34/34 [==============================] - 0s 4ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WWZ_Inclusive.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WWZ_WWZJetsTo4L2Nu.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "8628/8628 [==============================] - 33s 4ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WWZ_WWZJetsTo4L2Nu.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WW_WWTo1L1Nu2Q.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "142/142 [==============================] - 0s 3ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WW_WWTo1L1Nu2Q.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WW_WWTo2L2Nu.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "232/232 [==============================] - 1s 3ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WW_WWTo2L2Nu.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WW_WWTo4Q.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WW_WWTo4Q.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WZZ_Inclusive.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "49/49 [==============================] - 0s 4ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WZZ_Inclusive.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WZ_WZTo1L1Nu2Q.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "41/41 [==============================] - 0s 5ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WZ_WZTo1L1Nu2Q.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WZ_WZTo2Q2L.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "158/158 [==============================] - 1s 5ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WZ_WZTo2Q2L.root\u001b[0m\n",
      "\n",
      "Loading file: tree_WZ_WZTo3LNu.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "10056/10056 [==============================] - 35s 3ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_WZ_WZTo3LNu.root\u001b[0m\n",
      "\n",
      "Loading file: tree_ZGamma_ZGToLLG_01J.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "1167/1167 [==============================] - 6s 5ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_ZGamma_ZGToLLG_01J.root\u001b[0m\n",
      "\n",
      "Loading file: tree_ZZZ_Inclusive.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_ZZZ_Inclusive.root\u001b[0m\n",
      "\n",
      "Loading file: tree_ZZ_ZZTo2L2Nu.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "200/200 [==============================] - 1s 5ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_ZZ_ZZTo2L2Nu.root\u001b[0m\n",
      "\n",
      "Loading file: tree_ZZ_ZZTo2Q2L.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "310/310 [==============================] - 1s 4ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_ZZ_ZZTo2Q2L.root\u001b[0m\n",
      "\n",
      "Loading file: tree_ZZ_ZZTo2Q2Nu.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_ZZ_ZZTo2Q2Nu.root\u001b[0m\n",
      "\n",
      "Loading file: tree_ZZ_ZZTo4L.root\n",
      "X is scaled with min-max values.\n",
      "Model loaded: QCD-VLLD_mu-classifier\n",
      "43579/43579 [==============================] - 138s 3ms/step\n",
      "\u001b[1;32mFile written: ../../input_trees_modified/tree_2LSSinclusive_baseline_Sept17/tree_ZZ_ZZTo4L.root\u001b[0m\n",
      "\n",
      "CPU times: user 14min 36s, sys: 16min 19s, total: 30min 56s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.sparse as sparse #for numpy.array - pd.dataframe column conversion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "list_of_files = os.listdir(os.path.join(indir, jobname))\n",
    "train_var = ['njet', 'nbjet', 'dilep_mt', 'dilep_dR', 'HTMETllpt', 'STfrac', 'dphi_metdilep', 'dphi_metlep_max', 'dphi_metlep_min']\n",
    "# The list of training variables has to match with the trainning part.\n",
    "\n",
    "for f in list_of_files: \n",
    "\n",
    "    #Step1: Prepare the dataframe\n",
    "    print(f'Loading file: {f}')\n",
    "    filepath = os.path.join(indir, jobname, f)\n",
    "    sample = filepath.split(\"_\")[1]\n",
    "    subsample = \"_\".join(filepath.split(\"_\")[2:])\n",
    "    outdir = f'../../input_trees_modified/{jobname}'\n",
    "    os.makedirs(outdir, exist_ok=True)    \n",
    "    outfile = os.path.join(outdir, f)\n",
    "    \n",
    "    if os.path.exists(outfile): continue\n",
    "    \n",
    "    df = read_file_into_df(filepath)\n",
    "    if df.empty : \n",
    "        print(f\"\\033[0;31mWarning: Empty file written: {outfile}\\033[0m\\n\")\n",
    "        \n",
    "        continue\n",
    "\n",
    "    #Step2: Turn it into X matrix, y will be predicted by the models:\n",
    "    X= df[train_var].values\n",
    "    \n",
    "    #Step3 Load the model and evaulate:\n",
    "    for modelname, scorename in modeldict.items():\n",
    "        model_filename = f'{modelname}/model_{modelname}.h5'\n",
    "        min_filename = f'{modelname}/scaling_parameters_min.txt'\n",
    "        max_filename = f'{modelname}/scaling_parameters_max.txt'\n",
    "        ApplyMinMax(X, min_filename, max_filename)\n",
    "        print('X is scaled with min-max values.')\n",
    "        \n",
    "        mymodel = tf.keras.models.load_model(model_filename)\n",
    "        mymodel.load_weights(model_filename)\n",
    "        print(f'Model loaded: {modelname}')\n",
    "\n",
    "        y= mymodel.predict(X)\n",
    "        df[scorename] = y\n",
    "\n",
    "        break #model\n",
    "\n",
    "    write_df_into_file(df, os.path.join(outdir, f))\n",
    "    print(f'\\033[1;32mFile written: {outfile}\\033[0m\\n')\n",
    "\n",
    "    #break #file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906b52c-0b3f-449e-b320-643481aa04be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42787fbe-83b3-4ec3-b7fc-6f4873da811d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
