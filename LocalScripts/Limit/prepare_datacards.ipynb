{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4e3cef-2211-4c35-be69-01b17bf9d348",
   "metadata": {},
   "source": [
    "# Reading into histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5760d2-c749-4eae-97dc-26821631ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/10\n",
      "Modules loaded.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ROOT\n",
    "\n",
    "print('Modules loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015020cd-8eae-4c1b-ac54-3171383056ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile2018 = '../../InputJsons/lumidata_2018.json'\n",
    "\n",
    "with open(jsonfile2018,'r') as infile: filedict = json.load(infile)\n",
    "    \n",
    "jobnames = [\"hist_2LSS_SE2_Oct03_mm\"]\n",
    "histname = 'nnscore_qcd_vlld_combined'\n",
    "rebin = 10\n",
    "\n",
    "signals = ['VLLD_mu']\n",
    "tag = 'scaled_mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e82bc98-fda8-488d-ad54-fa55e809b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded.\n"
     ]
    }
   ],
   "source": [
    "sigdict = {\n",
    "    'VLLD_ele': {\n",
    "        'M100': {'mass': 100, 'xsec': 16.9,       'ngen': 110871, 'scale':1},\n",
    "        'M200': {'mass': 200, 'xsec': 1.36,       'ngen': 73730 , 'scale':1},\n",
    "        'M300': {'mass': 300, 'xsec': 0.291,      'ngen': 24753 , 'scale':1},\n",
    "        'M400': {'mass': 400, 'xsec': 0.0907,     'ngen': 24491 , 'scale':1},\n",
    "        'M600': {'mass': 600, 'xsec': 0.0149,     'ngen': 24611 , 'scale':1},\n",
    "        'M800': {'mass': 800, 'xsec': 0.00347,    'ngen': 23680 , 'scale':1},\n",
    "        'M1000': {'mass': 1000, 'xsec': 0.000971, 'ngen': 24286 , 'scale':1}\n",
    "    },\n",
    "    'VLLD_mu': {\n",
    "        'M100': {'mass': 100, 'xsec': 16.9,    'ngen': 111926, 'scale':50},\n",
    "        'M200': {'mass': 200, 'xsec': 1.36,    'ngen': 73908,  'scale':1},\n",
    "        'M300': {'mass': 300, 'xsec': 0.291,   'ngen': 25022,  'scale':1},\n",
    "        'M400': {'mass': 400, 'xsec': 0.0907,  'ngen': 24299 , 'scale':1},\n",
    "        'M600': {'mass': 600, 'xsec': 0.0149,  'ngen': 24890,  'scale':1},\n",
    "        'M800': {'mass': 800, 'xsec': 0.00347, 'ngen': 24763,  'scale':1}\n",
    "    }\n",
    "}\n",
    "\n",
    "bkgdict = {}\n",
    "\n",
    "def set_last_bin_as_overflow(hst):\n",
    "    lastBin  = hst.GetNbinsX()\n",
    "    content  = hst.GetBinContent(lastBin)\n",
    "    error    = hst.GetBinError(lastBin)\n",
    "    overflow = hst.GetBinContent(lastBin + 1)\n",
    "            \n",
    "    updated_content = content + overflow\n",
    "    updated_error   = (error**2 + overflow**2)**0.5\n",
    "            \n",
    "    hst.SetBinContent(lastBin, updated_content)\n",
    "    hst.SetBinError(lastBin, updated_error)\n",
    "            \n",
    "    # Handle underflow:\n",
    "    content_first = hst.GetBinContent(1)\n",
    "    error_first   = hst.GetBinError(1)\n",
    "    underflow     = hst.GetBinContent(0)\n",
    "            \n",
    "    updated_content_first = content_first + underflow\n",
    "    updated_error_first = (error_first**2 + underflow**2)**0.5\n",
    "            \n",
    "    hst.SetBinContent(1, updated_content_first)\n",
    "    hst.SetBinError(1, updated_error_first)\n",
    "\n",
    "print('Functions loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dc5bba-bd3a-48e9-89d2-2cc89a861782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 7.604369163513184, 15.656810760498047, 51.892940521240234, 221.5583953857422, 254.70211791992188, 353.43292236328125, 386.4912414550781, 374.7251892089844, 468.6051025390625, 577.6663208007812, 505.5987548828125, 508.2881164550781, 493.8747863769531, 373.5516052246094, 321.6204528808594] [0.0, 0.0, 0.0, 0.0, 0.0, 7.604369208022463, 11.0787801711085, 19.7482145388476, 41.95643406151715, 44.5624052790188, 52.34432197806308, 54.457588841284014, 53.832447659131596, 59.37956532954974, 67.02220411683332, 62.03849015817213, 62.84738291787642, 62.071569276726024, 54.2528806583707, 50.95392574806199] [4915.2691259384155]\n"
     ]
    }
   ],
   "source": [
    "for sample, subs in filedict.items():\n",
    "    if sample not in bkgdict: bkgdict[sample] = {}\n",
    "\n",
    "    for subsample, lumi in subs.items():\n",
    "        #if sample not in 'VLLD_mu': continue\n",
    "        if 'SingleMuon' in sample or 'EGamma' in sample: continue\n",
    "        #print(sample, subsample, lumi)\n",
    "        if subsample not in bkgdict[sample]: bkgdict[sample][subsample] = {}\n",
    "        \n",
    "        yields = []\n",
    "        errors = []\n",
    "        integrals = []\n",
    "\n",
    "        #Fill-up filedict and signal-dict with more information:\n",
    "        # Step1: Open the histogram and find out yield and error in in each bins.\n",
    "        for job in jobnames:\n",
    "            \n",
    "            input_dir = os.path.join('../input_hists', job)\n",
    "            filename = f'hst_{sample}_{subsample}.root'\n",
    "            filepath = os.path.join(input_dir, filename)\n",
    "            if not os.path.exists(filepath): continue\n",
    "\n",
    "            tfile = ROOT.TFile(filepath)\n",
    "            hist = tfile.Get(histname)\n",
    "\n",
    "            set_last_bin_as_overflow(hist)\n",
    "\n",
    "            #Pick lumi from signal:\n",
    "            if sample in signals:\n",
    "                lumi = sigdict[sample][subsample]['ngen']/sigdict[sample][subsample]['xsec']\n",
    "                \n",
    "            hist.Scale(59800/lumi)\n",
    "\n",
    "            hist.Rebin(rebin)\n",
    "            integral = hist.Integral()\n",
    "            integrals.append(integral)\n",
    "\n",
    "            nbins = hist.GetNbinsX()\n",
    "            #print(nbins)\n",
    "            for bin in range(1, nbins + 1):\n",
    "                yield_value = hist.GetBinContent(bin)\n",
    "                error_value = hist.GetBinError(bin)\n",
    "                yields.append(yield_value)\n",
    "                errors.append(error_value)\n",
    "\n",
    "            tfile.Close()\n",
    "\n",
    "        if 'VLL' not in sample:\n",
    "            bkgdict[sample][subsample]['yields'] = yields\n",
    "            bkgdict[sample][subsample]['errors'] = errors\n",
    "            bkgdict[sample][subsample]['integrals'] = integrals\n",
    "\n",
    "        if sample in signals:\n",
    "            if sample not in sigdict:            sigdict[sample] = {}\n",
    "            if subsample not in sigdict[sample]: sigdict[sample][subsample] = {}\n",
    "            sigdict[sample][subsample]['yields'] = yields\n",
    "            sigdict[sample][subsample]['errors'] = errors\n",
    "            sigdict[sample][subsample]['integrals'] = integrals\n",
    "            #print(f'Updated dictionary for {sample} {subsample}')\n",
    "            if sample == 'VLLD_mu' and subsample=='M100': print(yields, errors, integrals)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37def44f-fe3a-4034-bc10-3b305095419f",
   "metadata": {},
   "source": [
    "### Extracting background yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7432718-efa3-4789-8f80-eb45c4f20d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping background: WWZ WWZJetsTo4L2Nu\n",
      "Skipping background: WJetsNLO Inclusive\n",
      "Skipping background: WpWp WpWpJJQCD\n",
      "Skipping background: WGamma Inclusive\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bin     nBkg    nBkgErr\n",
      "1       0.00    0.001\n",
      "2       0.13    0.071\n",
      "3       0.33    0.110\n",
      "4       2.81    1.460\n",
      "5       5.93    2.413\n",
      "6       7.27    0.761\n",
      "7       23.24   2.151\n",
      "8       101.20  33.410\n",
      "9       128.65  8.768\n",
      "10      190.22  9.035\n",
      "11      320.50  35.436\n",
      "12      488.89  155.726\n",
      "13      301.45  16.295\n",
      "14      306.64  12.812\n",
      "15      340.33  33.818\n",
      "16      360.66  34.011\n",
      "17      328.55  11.486\n",
      "18      365.38  16.793\n",
      "19      397.56  13.092\n",
      "20      360.77  8.473\n"
     ]
    }
   ],
   "source": [
    "combined_bkg_yield = None\n",
    "combined_bkg_error = None\n",
    "\n",
    "# Loop through the samples and subsamples in bkgdict\n",
    "for sample, subs in bkgdict.items():\n",
    "    if 'VLL' in sample: continue\n",
    "        \n",
    "    for subsample, val in subs.items():\n",
    "        \n",
    "        # Check if 'yields' and 'errors' keys exist in the current subsample\n",
    "        if 'yields' not in val or 'errors' not in val:\n",
    "            print(f\"Warning: 'yields' or 'errors' not found for sample {sample}, subsample {subsample}.\")\n",
    "            continue\n",
    "\n",
    "        skip_samples = ['WWZ_WWZJetsTo4L2Nu', 'WJetsNLO_Inclusive', 'WpWp_WpWpJJQCD', 'WGamma_Inclusive']\n",
    "        if sample+'_'+subsample in skip_samples:\n",
    "            print(f'Skipping background: {sample} {subsample}')\n",
    "            continue\n",
    "            \n",
    "        # Get the yields and errors for the current subsample\n",
    "        yields = np.array(val['yields'])\n",
    "        errors = np.array(val['errors'])\n",
    "\n",
    "        if yields.size == 0 or errors.size == 0: continue\n",
    "\n",
    "        # Initialize the combined arrays if not already initialized\n",
    "        if combined_bkg_yield is None:\n",
    "            combined_bkg_yield = np.zeros_like(yields)\n",
    "            combined_bkg_error = np.zeros_like(errors)\n",
    "\n",
    "        # Add yields normally\n",
    "        combined_bkg_yield += yields\n",
    "\n",
    "        # Add errors in quadrature\n",
    "        combined_bkg_error = np.sqrt(combined_bkg_error**2 + errors**2)\n",
    "        #print(f\"Total yields and errors calculated for background: {sample} {subsample}\")\n",
    "\n",
    "# Now, `combined_bkg_yield` contains the total yields binwise\n",
    "# And `combined_bkg_error` contains the total errors binwise\n",
    "print('\\n'+'-'*100)\n",
    "print(f\"{'bin':<7} {'nBkg':<7} {'nBkgErr'}\")\n",
    "for i in range(combined_bkg_yield.shape[0]):\n",
    "    print(f'{i+1:<7} {combined_bkg_yield[i]:<7.2f} {combined_bkg_error[i]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b6437-cc0c-4b12-929c-14be86801060",
   "metadata": {},
   "source": [
    "### Extracting data yields (Setting it to background for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7b1b12-8215-4323-8d5e-6d58c8dd8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_bkg_yield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e1a62-6479-4ebb-a774-8217aed55256",
   "metadata": {},
   "source": [
    "# Preparing dataframe that holds yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd52b48-771e-400f-8040-8e12ed1f5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(sigdict, combined_data, combined_bkg_yield, combined_bkg_error, scalesignal=1):\n",
    "    nbins = len(combined_bkg_yield)  # Set nbins based on the size of combined_bkg_yield\n",
    "\n",
    "    # Dictionary to store dataframes for each sample and subsample\n",
    "    df_hierarchy = {}\n",
    "\n",
    "    for sample, subs in sigdict.items():\n",
    "        df_hierarchy[sample] = {}  # Initialize a dictionary for each sample\n",
    "        if sample not in signals: continue\n",
    "        \n",
    "        for subsample, val in subs.items():\n",
    "            #if sample != 'VLLD_mu': continue\n",
    "            #if subsample != 'M100': continue\n",
    "\n",
    "            # Initialize the dataframe to store information for the current subsample:\n",
    "            df = None\n",
    "\n",
    "            yields = np.array(val['yields'])\n",
    "            errors = np.array(val['errors'])\n",
    "\n",
    "            # If yields are zero, set a small value\n",
    "            yields[yields == 0] = 1e-7\n",
    "            \n",
    "            for ibin in range(nbins):\n",
    "\n",
    "                nbin = ibin + 1\n",
    "                \n",
    "                sig  = yields[ibin] if ibin < len(yields) else 0\n",
    "                dsig = errors[ibin] if ibin < len(errors) else 0\n",
    "\n",
    "                # Ensure the background is not zero\n",
    "                bkg  = combined_bkg_yield[ibin] if ibin < len(combined_bkg_yield) else 0\n",
    "                dbkg = combined_bkg_error[ibin] if ibin < len(combined_bkg_error) else 0\n",
    "                \n",
    "                if bkg == 0:\n",
    "                    pass\n",
    "                    #print(f'Removed bin {nbin} with zero background in {sample} - {subsample}')\n",
    "                    #continue  # Reject bins with zero background\n",
    "                \n",
    "                # Signal-to-background ratio\n",
    "                stob = 0\n",
    "                relative_dbkg = 0\n",
    "                if bkg != 0 :\n",
    "                    stob = sig / np.sqrt(bkg)\n",
    "                    relative_dbkg = dbkg/bkg\n",
    "                \n",
    "                deltaB = 1 + relative_dbkg\n",
    "                \n",
    "                # Create the entry for the dataframe as a row\n",
    "                rowdict = {\n",
    "                    'bin': nbin,\n",
    "                    'signal': sig,  # Store as numeric\n",
    "                    'nObs': combined_data[ibin],  # Store as numeric\n",
    "                    'nBkg': bkg,  # Store as numeric\n",
    "                    'bkg_err': dbkg,  # Store as numeric\n",
    "                    'S/sqrtB': stob,  # Store as numeric\n",
    "                    'deltaB': deltaB  # Store as numeric\n",
    "                }\n",
    "                rowdict['signal'] = rowdict['signal']/sigdict[sample][subsample]['scale']\n",
    "                #rowdict['signal'] = rowdict['signal']/scalesignal\n",
    "                new_row = pd.DataFrame([rowdict])\n",
    "\n",
    "                if df is None: df = new_row\n",
    "                else: df = pd.concat([df, new_row], ignore_index=True)\n",
    "                \n",
    "            # Sort and filter the dataframe\n",
    "            df = df.sort_values(by='S/sqrtB', ascending=False).reset_index(drop=True)\n",
    "\n",
    "            filter_condition = pd.Series([True] * len(df))\n",
    "            filter_condition = (df['deltaB']<1.10)\n",
    "            samplename = sample+'_'+subsample\n",
    "            '''\n",
    "            if   samplename == 'VLLD_mu_M100': filter_condition = filter_condition & (df['S/sqrtB'] > 0.001)\n",
    "            elif samplename == 'VLLD_mu_M200': filter_condition = filter_condition & (df['S/sqrtB'] > 0.1)\n",
    "            elif samplename == 'VLLD_mu_M300': filter_condition = filter_condition & (df['S/sqrtB'] > 0.1)\n",
    "            elif samplename == 'VLLD_mu_M400': filter_condition = filter_condition & (df['S/sqrtB'] > 0.01)\n",
    "            elif samplename == 'VLLD_mu_M600': filter_condition = filter_condition & (df['S/sqrtB'] > 0.001)\n",
    "            elif samplename == 'VLLD_mu_M800': filter_condition = filter_condition & (df['S/sqrtB'] > 0.0001)\n",
    "            ''' \n",
    "            df = df.loc[filter_condition]\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            # Store the DataFrame in the dictionary\n",
    "            df_hierarchy[sample][subsample] = df\n",
    "\n",
    "    return df_hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f32180-5e22-4637-9813-f2ac31c99e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>signal</th>\n",
       "      <th>nObs</th>\n",
       "      <th>nBkg</th>\n",
       "      <th>bkg_err</th>\n",
       "      <th>S/sqrtB</th>\n",
       "      <th>deltaB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>43.413019</td>\n",
       "      <td>360.766683</td>\n",
       "      <td>360.766683</td>\n",
       "      <td>8.473456</td>\n",
       "      <td>2.285634e-02</td>\n",
       "      <td>1.023487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>11.345303</td>\n",
       "      <td>397.563738</td>\n",
       "      <td>397.563738</td>\n",
       "      <td>13.091553</td>\n",
       "      <td>5.690006e-03</td>\n",
       "      <td>1.032929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>9.083211</td>\n",
       "      <td>365.382555</td>\n",
       "      <td>365.382555</td>\n",
       "      <td>16.792507</td>\n",
       "      <td>4.751881e-03</td>\n",
       "      <td>1.045959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>7.130785</td>\n",
       "      <td>328.547888</td>\n",
       "      <td>328.547888</td>\n",
       "      <td>11.486160</td>\n",
       "      <td>3.934033e-03</td>\n",
       "      <td>1.034960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>5.917874</td>\n",
       "      <td>306.643638</td>\n",
       "      <td>306.643638</td>\n",
       "      <td>12.812433</td>\n",
       "      <td>3.379471e-03</td>\n",
       "      <td>1.041783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>6.121801</td>\n",
       "      <td>340.326766</td>\n",
       "      <td>340.326766</td>\n",
       "      <td>33.817990</td>\n",
       "      <td>3.318418e-03</td>\n",
       "      <td>1.099369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>4.463984</td>\n",
       "      <td>360.664078</td>\n",
       "      <td>360.664078</td>\n",
       "      <td>34.010652</td>\n",
       "      <td>2.350559e-03</td>\n",
       "      <td>1.094300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>1.566084</td>\n",
       "      <td>301.451255</td>\n",
       "      <td>301.451255</td>\n",
       "      <td>16.294924</td>\n",
       "      <td>9.020001e-04</td>\n",
       "      <td>1.054055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.774828</td>\n",
       "      <td>190.219543</td>\n",
       "      <td>190.219543</td>\n",
       "      <td>9.035460</td>\n",
       "      <td>5.617947e-04</td>\n",
       "      <td>1.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>23.241538</td>\n",
       "      <td>23.241538</td>\n",
       "      <td>2.150899</td>\n",
       "      <td>2.074281e-08</td>\n",
       "      <td>1.092545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>128.651601</td>\n",
       "      <td>128.651601</td>\n",
       "      <td>8.767759</td>\n",
       "      <td>8.816423e-09</td>\n",
       "      <td>1.068151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin     signal        nObs        nBkg    bkg_err       S/sqrtB    deltaB\n",
       "0    20  43.413019  360.766683  360.766683   8.473456  2.285634e-02  1.023487\n",
       "1    19  11.345303  397.563738  397.563738  13.091553  5.690006e-03  1.032929\n",
       "2    18   9.083211  365.382555  365.382555  16.792507  4.751881e-03  1.045959\n",
       "3    17   7.130785  328.547888  328.547888  11.486160  3.934033e-03  1.034960\n",
       "4    14   5.917874  306.643638  306.643638  12.812433  3.379471e-03  1.041783\n",
       "5    15   6.121801  340.326766  340.326766  33.817990  3.318418e-03  1.099369\n",
       "6    16   4.463984  360.664078  360.664078  34.010652  2.350559e-03  1.094300\n",
       "7    13   1.566084  301.451255  301.451255  16.294924  9.020001e-04  1.054055\n",
       "8    10   0.774828  190.219543  190.219543   9.035460  5.617947e-04  1.047500\n",
       "9     7   0.000010   23.241538   23.241538   2.150899  2.074281e-08  1.092545\n",
       "10    9   0.000010  128.651601  128.651601   8.767759  8.816423e-09  1.068151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scale = 0.01\n",
    "df = prepare_df(sigdict, combined_data, combined_bkg_yield, combined_bkg_error, scalesignal = scale)\n",
    "display(df['VLLD_mu']['M800'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0710dda-bf15-4edd-9177-4f7a1d56778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sig = 89.82\n",
      "total bkg = 3103.46\n",
      "nbin    signal  nObs    nBkg    bkgErr  S/sqrtB deltaB\n",
      "1\t43.41\t360.77\t360.77\t8.47\t0.02\t1.02\n",
      "2\t11.35\t397.56\t397.56\t13.09\t0.01\t1.03\n",
      "3\t9.08\t365.38\t365.38\t16.79\t0.00\t1.05\n",
      "4\t7.13\t328.55\t328.55\t11.49\t0.00\t1.03\n",
      "5\t5.92\t306.64\t306.64\t12.81\t0.00\t1.04\n",
      "6\t6.12\t340.33\t340.33\t33.82\t0.00\t1.10\n",
      "7\t4.46\t360.66\t360.66\t34.01\t0.00\t1.09\n",
      "8\t1.57\t301.45\t301.45\t16.29\t0.00\t1.05\n",
      "9\t0.77\t190.22\t190.22\t9.04\t0.00\t1.05\n",
      "10\t0.00\t23.24\t23.24\t2.15\t0.00\t1.09\n",
      "11\t0.00\t128.65\t128.65\t8.77\t0.00\t1.07\n"
     ]
    }
   ],
   "source": [
    "df_test = df['VLLD_mu']['M800']\n",
    "\n",
    "total_sig = np.sum(df_test['signal'])\n",
    "total_bkg = np.sum(df_test['nBkg'])\n",
    "\n",
    "print(f'total sig = {total_sig:.2f}')\n",
    "print(f'total bkg = {total_bkg:.2f}')\n",
    "print(f\"{'nbin':<7} {'signal':<7} {'nObs':<7} {'nBkg':<7} {'bkgErr':<7} {'S/sqrtB':<7} {'deltaB'}\")\n",
    "for index, row in df_test.iterrows():\n",
    "    print(f\"{index+1}\\t{row['signal']:.2f}\\t{row['nObs']:.2f}\\t{row['nBkg']:.2f}\\t{row['bkg_err']:.2f}\\t{row['S/sqrtB']:.2f}\\t{row['deltaB']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77a15c-653a-4332-9827-59e1793e3f60",
   "metadata": {},
   "source": [
    "## Writing into text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80fe754-e2e9-4dd4-99b9-406e20477867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funtions loaded.\n"
     ]
    }
   ],
   "source": [
    "def write_df_to_file(df, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        # Write the header with fixed widths\n",
    "        header = f\"{'bin':<10}{'signal':<10}{'nObs':<10}{'nBkg':<10}{'bkg_err':<10}{'S/sqrtB':<10}{'deltaB':<10}\"\n",
    "        f.write(header + '\\n')\n",
    "        \n",
    "        # Write the data rows\n",
    "        for index, row in df.iterrows():\n",
    "            line = f\"{int(row['bin']):<10}\"\n",
    "            line += f\"{float(row['signal']):<10.2f}\"\n",
    "            line += f\"{float(row['nObs']):<10.2f}\"\n",
    "            line += f\"{float(row['nBkg']):<10.2f}\"\n",
    "            line += f\"{float(row['bkg_err']):<10.2f}\"\n",
    "            line += f\"{float(row['S/sqrtB']):<10.2f}\"\n",
    "            line += f\"{float(row['deltaB']):<10.4f}\"\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "def write_datacard(df, datacard):\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    num_bins = len(df)  # Total number of bins\n",
    "    \n",
    "    if num_bins == 0:\n",
    "        print(f'Warning: Zero bins detected! SKipping file {datacard}')\n",
    "        return\n",
    "        \n",
    "    #print(f'Processing {num_bins} bins ')\n",
    "    \n",
    "    with open(datacard, 'w') as f:\n",
    "        #header information\n",
    "        f.write(f\"imax {num_bins}                          # number of channels\\n\")\n",
    "        f.write(f\"jmax 1                           # number of backgrounds\\n\")\n",
    "        f.write(f\"kmax {num_bins}                          # number of nuisance parameters\\n\")\n",
    "        f.write(\"------------\\n\")\n",
    "        \n",
    "        # Bin section\n",
    "        f.write(f\"{'bin':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"bin{i + 1}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "        \n",
    "        # Observation section\n",
    "        f.write(f\"{'observation':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"{int(df['nObs'].iat[i])}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "        f.write(\"------------\\n\")\n",
    "\n",
    "        # Bin-Bin section\n",
    "        f.write(f\"{'bin':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"bin{i + 1}\\tbin{i + 1}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "        \n",
    "        #Process section\n",
    "        f.write(f\"{'process':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += \"sig\\tbkg\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "        #Process ID section:\n",
    "        f.write(f\"{'process':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"{-1*(i + 1)}\\t{(i + 1)}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "        # Rate section\n",
    "        f.write(f\"{'rate':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"{df['signal'].at[i]:.2f}\\t{df['nBkg'].at[i]:.2f}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "        f.write(\"------------\\n\")\n",
    "\n",
    "        #uncertainty:\n",
    "        for i in range(num_bins):\n",
    "            uncertainty_line = f\"xs{i + 1:<6}lnN\\t\"\n",
    "            values = []\n",
    "            for j in range(num_bins):\n",
    "                if j == i: # Diagonal element\n",
    "                    values.append(\"-\")  # Signal uncertainty\n",
    "                    uncertainty_value = df['deltaB'][i]\n",
    "                    values.append(f\"{uncertainty_value:.5f}\") # Background uncertainty\n",
    "                else:\n",
    "                    values.append(\"-\") # Signal uncertainty\n",
    "                    values.append(\"-\") # Background uncertainty\n",
    "            uncertainty_line += \"\\t\".join(values)\n",
    "            f.write(uncertainty_line + \"\\n\")\n",
    "            \n",
    "    print(f'Wrote file: {datacard}')  \n",
    "    \n",
    "print('Funtions loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f5c09d1-435f-41fc-b926-34528ab26c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file: test_scale0.01.txt\n"
     ]
    }
   ],
   "source": [
    "#write_datacard(df['VLLD_mu']['M800'], f'test_scale{scale}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "656ae9dc-051e-4780-aff3-c404f036d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote text file: yields/scaled_mm/yields_VLLD_mu_M100_scaled_mm.txt\n",
      "Wrote text file: yields/scaled_mm/yields_VLLD_mu_M200_scaled_mm.txt\n",
      "Wrote text file: yields/scaled_mm/yields_VLLD_mu_M300_scaled_mm.txt\n",
      "Wrote text file: yields/scaled_mm/yields_VLLD_mu_M400_scaled_mm.txt\n",
      "Wrote text file: yields/scaled_mm/yields_VLLD_mu_M600_scaled_mm.txt\n",
      "Wrote text file: yields/scaled_mm/yields_VLLD_mu_M800_scaled_mm.txt\n",
      "\n",
      "Warning: Information for the following samples are not found.\n",
      "['VLLD_ele_M100', 'VLLD_ele_M200', 'VLLD_ele_M300', 'VLLD_ele_M400', 'VLLD_ele_M600', 'VLLD_ele_M800', 'VLLD_ele_M1000']\n"
     ]
    }
   ],
   "source": [
    "not_found = []\n",
    "\n",
    "for sample, subs in sigdict.items():\n",
    "    for subsample, val in subs.items():\n",
    "        outfolder = f\"yields/{tag}\"\n",
    "        yieldfile = f\"{outfolder}/yields_{sample}_{subsample}_{tag}.txt\"\n",
    "        os.makedirs(outfolder, exist_ok=True)\n",
    "        \n",
    "        # Check if the DataFrame for the current sample and subsample exists\n",
    "        if sample in df and subsample in df[sample]:\n",
    "            write_df_to_file(df[sample][subsample], yieldfile)\n",
    "            #pass\n",
    "            print(f'Wrote text file: {yieldfile}')\n",
    "        else: not_found.append(f'{sample}_{subsample}')\n",
    "\n",
    "print('\\nWarning: Information for the following samples are not found.')\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742372ce-3001-4469-8ea7-68c9ee1bf192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: Information for the following samples are not found.\n",
      "['VLLD_ele_M100', 'VLLD_ele_M200', 'VLLD_ele_M300', 'VLLD_ele_M400', 'VLLD_ele_M600', 'VLLD_ele_M800', 'VLLD_ele_M1000']\n"
     ]
    }
   ],
   "source": [
    "not_found = []\n",
    "\n",
    "for sample, subs in sigdict.items():\n",
    "    for subsample, val in subs.items():\n",
    "        outfolder = f\"datacards/{tag}\"\n",
    "        datacard = f\"{outfolder}/datacard_{sample}_{subsample}_{tag}.txt\"\n",
    "        os.makedirs(outfolder, exist_ok=True)\n",
    "\n",
    "        # Check if the DataFrame for the current sample and subsample exists\n",
    "        if sample in df and subsample in df[sample]:\n",
    "            write_datacard(df[sample][subsample], datacard)\n",
    "            #pass\n",
    "            \n",
    "        else: not_found.append(f'{sample}_{subsample}')\n",
    "\n",
    "print('\\nWarning: Information for the following samples are not found.')\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8cf2a-8997-4f2f-b01c-fe5e1f386ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
