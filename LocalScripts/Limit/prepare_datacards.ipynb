{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4e3cef-2211-4c35-be69-01b17bf9d348",
   "metadata": {},
   "source": [
    "# Reading into histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5760d2-c749-4eae-97dc-26821631ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/10\n",
      "Modules loaded.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ROOT\n",
    "\n",
    "print('Modules loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015020cd-8eae-4c1b-ac54-3171383056ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile2018 = '../../InputJsons/lumidata_2018.json'\n",
    "\n",
    "with open(jsonfile2018,'r') as infile: filedict = json.load(infile)\n",
    "    \n",
    "jobnames = [\"hist_2LSS_SE2_Oct03_mm\"]\n",
    "histname = 'nnscore_qcd_vlld_combined'\n",
    "rebin = 5\n",
    "\n",
    "signals = ['VLLD_ele', 'VLLD_mu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e82bc98-fda8-488d-ad54-fa55e809b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded.\n"
     ]
    }
   ],
   "source": [
    "sigdict = {\n",
    "    'VLLD_ele': {\n",
    "        'M100': {'mass': 100, 'xsec': 16.9, 'ngen': 110871},\n",
    "        'M200': {'mass': 200, 'xsec': 1.36, 'ngen': 73730},\n",
    "        'M300': {'mass': 300, 'xsec': 0.291, 'ngen': 24753},\n",
    "        'M400': {'mass': 400, 'xsec': 0.0907, 'ngen': 24491},\n",
    "        'M600': {'mass': 600, 'xsec': 0.0149, 'ngen': 24611},\n",
    "        'M800': {'mass': 800, 'xsec': 0.00347, 'ngen': 23680},\n",
    "        'M1000': {'mass': 1000, 'xsec': 0.000971, 'ngen': 24286}\n",
    "    },\n",
    "    'VLLD_mu': {\n",
    "        'M100': {'mass': 100, 'xsec': 16.9, 'ngen': 111926},\n",
    "        'M200': {'mass': 200, 'xsec': 1.36, 'ngen': 73908},\n",
    "        'M300': {'mass': 300, 'xsec': 0.291, 'ngen': 25022},\n",
    "        'M400': {'mass': 400, 'xsec': 0.0907, 'ngen': 24299},\n",
    "        'M600': {'mass': 600, 'xsec': 0.0149, 'ngen': 24890},\n",
    "        'M800': {'mass': 800, 'xsec': 0.00347, 'ngen': 24763}\n",
    "    }\n",
    "}\n",
    "\n",
    "bkgdict = {}\n",
    "\n",
    "def set_last_bin_as_overflow(hst):\n",
    "    lastBin  = hst.GetNbinsX()\n",
    "    content  = hst.GetBinContent(lastBin)\n",
    "    error    = hst.GetBinError(lastBin)\n",
    "    overflow = hst.GetBinContent(lastBin + 1)\n",
    "            \n",
    "    updated_content = content + overflow\n",
    "    updated_error   = (error**2 + overflow**2)**0.5\n",
    "            \n",
    "    hst.SetBinContent(lastBin, updated_content)\n",
    "    hst.SetBinError(lastBin, updated_error)\n",
    "            \n",
    "    # Handle underflow:\n",
    "    content_first = hst.GetBinContent(1)\n",
    "    error_first   = hst.GetBinError(1)\n",
    "    underflow     = hst.GetBinContent(0)\n",
    "            \n",
    "    updated_content_first = content_first + underflow\n",
    "    updated_error_first = (error_first**2 + underflow**2)**0.5\n",
    "            \n",
    "    hst.SetBinContent(1, updated_content_first)\n",
    "    hst.SetBinError(1, updated_error_first)\n",
    "\n",
    "print('Functions loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dc5bba-bd3a-48e9-89d2-2cc89a861782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.604369163513184, 7.5355706214904785, 8.121240615844727, 16.020751953125, 35.872188568115234, 63.90382766723633, 157.65457153320312, 106.15678405761719, 148.5453338623047, 140.87515258789062, 212.5577850341797, 195.47897338867188, 191.01226806640625, 187.77584838867188, 186.9493408203125, 251.87643432617188, 216.72866821289062, 256.46636962890625, 321.199951171875, 240.88897705078125, 264.70977783203125, 215.229736328125, 293.0583801269531, 262.9051513671875, 230.9696502685547, 162.87310791015625, 210.67849731445312, 216.32093811035156, 105.29950714111328] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.604369208022463, 7.535570499957379, 8.121240503760431, 11.384601015956521, 16.136382406841793, 22.604668296493273, 35.34644720992406, 28.479790523490554, 34.27403530355917, 33.32769853849903, 40.363257468520395, 38.59216143910314, 38.42231197968886, 38.471461283933465, 37.65473526200857, 43.416359857584965, 40.508671607977355, 44.782875463007436, 49.864515539040745, 42.786658004119566, 44.92300254818383, 40.834340945827556, 47.77394833113646, 45.35952917002266, 42.37207601651425, 35.77357138784068, 40.787579603238036, 41.7233232004288, 29.248364915864517] [4915.2691531181335]\n"
     ]
    }
   ],
   "source": [
    "for sample, subs in filedict.items():\n",
    "    if sample not in bkgdict: bkgdict[sample] = {}\n",
    "\n",
    "    for subsample, lumi in subs.items():\n",
    "        #if sample not in 'VLLD_mu': continue\n",
    "        if 'SingleMuon' in sample or 'EGamma' in sample: continue\n",
    "        #print(sample, subsample, lumi)\n",
    "        if subsample not in bkgdict[sample]: bkgdict[sample][subsample] = {}\n",
    "        \n",
    "        yields = []\n",
    "        errors = []\n",
    "        integrals = []\n",
    "\n",
    "        #Fill-up filedict and signal-dict with more information:\n",
    "        # Step1: Open the histogram and find out yield and error in in each bins.\n",
    "        for job in jobnames:\n",
    "            \n",
    "            input_dir = os.path.join('../input_hists', job)\n",
    "            filename = f'hst_{sample}_{subsample}.root'\n",
    "            filepath = os.path.join(input_dir, filename)\n",
    "            if not os.path.exists(filepath): continue\n",
    "\n",
    "            tfile = ROOT.TFile(filepath)\n",
    "            hist = tfile.Get(histname)\n",
    "\n",
    "            set_last_bin_as_overflow(hist)\n",
    "\n",
    "            #Pick lumi from signal:\n",
    "            if sample in signals:\n",
    "                lumi = sigdict[sample][subsample]['ngen']/sigdict[sample][subsample]['xsec']\n",
    "                \n",
    "            hist.Scale(59800/lumi)\n",
    "\n",
    "            hist.Rebin(rebin)\n",
    "            integral = hist.Integral()\n",
    "            integrals.append(integral)\n",
    "\n",
    "            nbins = hist.GetNbinsX()\n",
    "            #print(nbins)\n",
    "            for bin in range(1, nbins + 1):\n",
    "                yield_value = hist.GetBinContent(bin)\n",
    "                error_value = hist.GetBinError(bin)\n",
    "                yields.append(yield_value)\n",
    "                errors.append(error_value)\n",
    "\n",
    "            tfile.Close()\n",
    "\n",
    "        if 'VLL' not in sample:\n",
    "            bkgdict[sample][subsample]['yields'] = yields\n",
    "            bkgdict[sample][subsample]['errors'] = errors\n",
    "            bkgdict[sample][subsample]['integrals'] = integrals\n",
    "\n",
    "        if sample in signals:\n",
    "            if sample not in sigdict:            sigdict[sample] = {}\n",
    "            if subsample not in sigdict[sample]: sigdict[sample][subsample] = {}\n",
    "            sigdict[sample][subsample]['yields'] = yields\n",
    "            sigdict[sample][subsample]['errors'] = errors\n",
    "            sigdict[sample][subsample]['integrals'] = integrals\n",
    "            #print(f'Updated dictionary for {sample} {subsample}')\n",
    "            if sample == 'VLLD_mu' and subsample=='M100': print(yields, errors, integrals)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37def44f-fe3a-4034-bc10-3b305095419f",
   "metadata": {},
   "source": [
    "### Extracting background yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7432718-efa3-4789-8f80-eb45c4f20d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping background: WWZ WWZJetsTo4L2Nu\n",
      "Skipping background: WJetsNLO Inclusive\n",
      "Skipping background: WpWp WpWpJJQCD\n",
      "Skipping background: WGamma Inclusive\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bin     nBkg    nBkgErr\n",
      "1       0.00    0.001\n",
      "2       0.00    0.000\n",
      "3       0.06    0.043\n",
      "4       0.08    0.056\n",
      "5       0.14    0.072\n",
      "6       0.18    0.083\n",
      "7       1.19    0.928\n",
      "8       1.62    1.127\n",
      "9       1.91    1.276\n",
      "10      4.02    2.048\n",
      "11      2.32    0.286\n",
      "12      4.95    0.705\n",
      "13      8.16    0.730\n",
      "14      15.08   2.023\n",
      "15      62.24   32.785\n",
      "16      38.96   6.431\n",
      "17      51.64   5.293\n",
      "18      77.01   6.990\n",
      "19      83.96   5.892\n",
      "20      106.26  6.850\n",
      "21      142.09  14.000\n",
      "22      178.41  32.554\n",
      "23      342.65  155.505\n",
      "24      146.25  8.289\n",
      "25      148.68  13.197\n",
      "26      152.77  9.559\n",
      "27      155.94  8.853\n",
      "28      150.70  9.262\n",
      "29      193.03  32.671\n",
      "30      147.29  8.732\n",
      "31      200.59  33.021\n",
      "32      160.08  8.145\n",
      "33      161.35  7.941\n",
      "34      167.20  8.299\n",
      "35      181.57  13.900\n",
      "36      183.81  9.422\n",
      "37      193.77  9.300\n",
      "38      203.79  9.214\n",
      "39      193.24  5.138\n",
      "40      167.53  6.738\n"
     ]
    }
   ],
   "source": [
    "combined_bkg_yield = None\n",
    "combined_bkg_error = None\n",
    "\n",
    "# Loop through the samples and subsamples in bkgdict\n",
    "for sample, subs in bkgdict.items():\n",
    "    if 'VLL' in sample: continue\n",
    "        \n",
    "    for subsample, val in subs.items():\n",
    "        \n",
    "        # Check if 'yields' and 'errors' keys exist in the current subsample\n",
    "        if 'yields' not in val or 'errors' not in val:\n",
    "            print(f\"Warning: 'yields' or 'errors' not found for sample {sample}, subsample {subsample}.\")\n",
    "            continue\n",
    "\n",
    "        skip_samples = ['WWZ_WWZJetsTo4L2Nu', 'WJetsNLO_Inclusive', 'WpWp_WpWpJJQCD', 'WGamma_Inclusive']\n",
    "        if sample+'_'+subsample in skip_samples:\n",
    "            print(f'Skipping background: {sample} {subsample}')\n",
    "            continue\n",
    "            \n",
    "        # Get the yields and errors for the current subsample\n",
    "        yields = np.array(val['yields'])\n",
    "        errors = np.array(val['errors'])\n",
    "\n",
    "        if yields.size == 0 or errors.size == 0: continue\n",
    "\n",
    "        # Initialize the combined arrays if not already initialized\n",
    "        if combined_bkg_yield is None:\n",
    "            combined_bkg_yield = np.zeros_like(yields)\n",
    "            combined_bkg_error = np.zeros_like(errors)\n",
    "\n",
    "        # Add yields normally\n",
    "        combined_bkg_yield += yields\n",
    "\n",
    "        # Add errors in quadrature\n",
    "        combined_bkg_error = np.sqrt(combined_bkg_error**2 + errors**2)\n",
    "        #print(f\"Total yields and errors calculated for background: {sample} {subsample}\")\n",
    "\n",
    "# Now, `combined_bkg_yield` contains the total yields binwise\n",
    "# And `combined_bkg_error` contains the total errors binwise\n",
    "print('\\n'+'-'*100)\n",
    "print(f\"{'bin':<7} {'nBkg':<7} {'nBkgErr'}\")\n",
    "for i in range(combined_bkg_yield.shape[0]):\n",
    "    print(f'{i+1:<7} {combined_bkg_yield[i]:<7.2f} {combined_bkg_error[i]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b6437-cc0c-4b12-929c-14be86801060",
   "metadata": {},
   "source": [
    "### Extracting data yields (Setting it to background for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7b1b12-8215-4323-8d5e-6d58c8dd8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_bkg_yield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e1a62-6479-4ebb-a774-8217aed55256",
   "metadata": {},
   "source": [
    "# Preparing dataframe that holds yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd52b48-771e-400f-8040-8e12ed1f5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(sigdict, combined_data, combined_bkg_yield, combined_bkg_error):\n",
    "    nbins = len(combined_bkg_yield)  # Set nbins based on the size of combined_bkg_yield\n",
    "\n",
    "    # Dictionary to store dataframes for each sample and subsample\n",
    "    df_hierarchy = {}\n",
    "\n",
    "    for sample, subs in sigdict.items():\n",
    "        df_hierarchy[sample] = {}  # Initialize a dictionary for each sample\n",
    "        \n",
    "        for subsample, val in subs.items():\n",
    "            #if sample != 'VLLD_mu': continue\n",
    "            #if subsample != 'M100': continue\n",
    "\n",
    "            # Initialize the dataframe to store information for the current subsample:\n",
    "            df = None\n",
    "\n",
    "            yields = np.array(val['yields'])\n",
    "            errors = np.array(val['errors'])\n",
    "\n",
    "            # If yields are zero, set a small value\n",
    "            yields[yields == 0] = 1e-7\n",
    "            \n",
    "            for ibin in range(nbins):\n",
    "\n",
    "                nbin = ibin + 1\n",
    "                \n",
    "                sig  = yields[ibin] if ibin < len(yields) else 0\n",
    "                dsig = errors[ibin] if ibin < len(errors) else 0\n",
    "\n",
    "                # Ensure the background is not zero\n",
    "                bkg  = combined_bkg_yield[ibin] if ibin < len(combined_bkg_yield) else 0\n",
    "                dbkg = combined_bkg_error[ibin] if ibin < len(combined_bkg_error) else 0\n",
    "                \n",
    "                if bkg == 0:\n",
    "                    pass\n",
    "                    #print(f'Removed bin {nbin} with zero background in {sample} - {subsample}')\n",
    "                    #continue  # Reject bins with zero background\n",
    "                \n",
    "                # Signal-to-background ratio\n",
    "                stob = 0\n",
    "                relative_dbkg = 0\n",
    "                if bkg != 0 :\n",
    "                    stob = sig / np.sqrt(bkg)\n",
    "                    relative_dbkg = dbkg/bkg\n",
    "                \n",
    "                deltaB = 1 + relative_dbkg\n",
    "                \n",
    "                # Create the entry for the dataframe as a row\n",
    "                new_row = pd.DataFrame([{\n",
    "                    'bin': nbin,\n",
    "                    'signal': sig,  # Store as numeric\n",
    "                    'nObs': combined_data[ibin],  # Store as numeric\n",
    "                    'nBkg': bkg,  # Store as numeric\n",
    "                    'bkg_err': dbkg,  # Store as numeric\n",
    "                    'S/sqrtB': stob,  # Store as numeric\n",
    "                    'deltaB': deltaB  # Store as numeric\n",
    "                }])\n",
    "\n",
    "                if df is None: df = new_row\n",
    "                else: df = pd.concat([df, new_row], ignore_index=True)\n",
    "                \n",
    "            # Sort and filter the dataframe\n",
    "            df = df.sort_values(by='S/sqrtB', ascending=False).reset_index(drop=True)\n",
    "\n",
    "            filter_condition = pd.Series([True] * len(df))\n",
    "            filter_condition =  (df['nBkg'] > 0.1) & (df['deltaB']<1.10)\n",
    "            samplename = sample+'_'+subsample\n",
    "            if   samplename == 'VLLD_mu_M100': filter_condition = filter_condition & (df['S/sqrtB'] > 1)\n",
    "            elif samplename == 'VLLD_mu_M200': filter_condition = filter_condition & (df['S/sqrtB'] > 0.1)\n",
    "            elif samplename == 'VLLD_mu_M300': filter_condition = filter_condition & (df['S/sqrtB'] > 0.1)\n",
    "            elif samplename == 'VLLD_mu_M400': filter_condition = filter_condition & (df['S/sqrtB'] > 0.01)\n",
    "            elif samplename == 'VLLD_mu_M600': filter_condition = filter_condition & (df['S/sqrtB'] > 0.001)\n",
    "            elif samplename == 'VLLD_mu_M800': filter_condition = filter_condition & (df['S/sqrtB'] > 0.0001)\n",
    "                \n",
    "            df = df.loc[filter_condition]\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            # Store the DataFrame in the dictionary\n",
    "            df_hierarchy[sample][subsample] = df\n",
    "\n",
    "    return df_hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f32180-5e22-4637-9813-f2ac31c99e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>signal</th>\n",
       "      <th>nObs</th>\n",
       "      <th>nBkg</th>\n",
       "      <th>bkg_err</th>\n",
       "      <th>S/sqrtB</th>\n",
       "      <th>deltaB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1.765579</td>\n",
       "      <td>167.530924</td>\n",
       "      <td>167.530924</td>\n",
       "      <td>6.738142</td>\n",
       "      <td>0.136408</td>\n",
       "      <td>1.040220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0.586693</td>\n",
       "      <td>193.235768</td>\n",
       "      <td>193.235768</td>\n",
       "      <td>5.137792</td>\n",
       "      <td>0.042205</td>\n",
       "      <td>1.026588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>0.291319</td>\n",
       "      <td>193.772971</td>\n",
       "      <td>193.772971</td>\n",
       "      <td>9.299646</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>1.047992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>161.349823</td>\n",
       "      <td>161.349823</td>\n",
       "      <td>7.940673</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>1.049214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>0.240907</td>\n",
       "      <td>181.569012</td>\n",
       "      <td>181.569012</td>\n",
       "      <td>13.900176</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>1.076556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38</td>\n",
       "      <td>0.223901</td>\n",
       "      <td>203.790762</td>\n",
       "      <td>203.790762</td>\n",
       "      <td>9.214410</td>\n",
       "      <td>0.015684</td>\n",
       "      <td>1.045215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>0.158996</td>\n",
       "      <td>183.813541</td>\n",
       "      <td>183.813541</td>\n",
       "      <td>9.421964</td>\n",
       "      <td>0.011727</td>\n",
       "      <td>1.051258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>0.142982</td>\n",
       "      <td>167.198069</td>\n",
       "      <td>167.198069</td>\n",
       "      <td>8.299252</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>1.049637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28</td>\n",
       "      <td>0.132026</td>\n",
       "      <td>150.700014</td>\n",
       "      <td>150.700014</td>\n",
       "      <td>9.261721</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>1.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>0.063981</td>\n",
       "      <td>152.766496</td>\n",
       "      <td>152.766496</td>\n",
       "      <td>9.558797</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>1.062571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>0.061583</td>\n",
       "      <td>147.294859</td>\n",
       "      <td>147.294859</td>\n",
       "      <td>8.731923</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>1.059282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>0.041873</td>\n",
       "      <td>160.078909</td>\n",
       "      <td>160.078909</td>\n",
       "      <td>8.145170</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>1.050882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>155.943622</td>\n",
       "      <td>155.943622</td>\n",
       "      <td>8.853190</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>1.056772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>0.034822</td>\n",
       "      <td>146.245562</td>\n",
       "      <td>146.245562</td>\n",
       "      <td>8.288576</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>1.056676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>0.030466</td>\n",
       "      <td>148.684755</td>\n",
       "      <td>148.684755</td>\n",
       "      <td>13.196740</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>1.088757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin    signal        nObs        nBkg    bkg_err   S/sqrtB    deltaB\n",
       "0    40  1.765579  167.530924  167.530924   6.738142  0.136408  1.040220\n",
       "1    39  0.586693  193.235768  193.235768   5.137792  0.042205  1.026588\n",
       "2    37  0.291319  193.772971  193.772971   9.299646  0.020928  1.047992\n",
       "3    33  0.240100  161.349823  161.349823   7.940673  0.018902  1.049214\n",
       "4    35  0.240907  181.569012  181.569012  13.900176  0.017878  1.076556\n",
       "5    38  0.223901  203.790762  203.790762   9.214410  0.015684  1.045215\n",
       "6    36  0.158996  183.813541  183.813541   9.421964  0.011727  1.051258\n",
       "7    34  0.142982  167.198069  167.198069   8.299252  0.011058  1.049637\n",
       "8    28  0.132026  150.700014  150.700014   9.261721  0.010755  1.061458\n",
       "9    26  0.063981  152.766496  152.766496   9.558797  0.005177  1.062571\n",
       "10   30  0.061583  147.294859  147.294859   8.731923  0.005074  1.059282\n",
       "11   32  0.041873  160.078909  160.078909   8.145170  0.003310  1.050882\n",
       "12   27  0.036308  155.943622  155.943622   8.853190  0.002908  1.056772\n",
       "13   24  0.034822  146.245562  146.245562   8.288576  0.002879  1.056676\n",
       "14   25  0.030466  148.684755  148.684755  13.196740  0.002499  1.088757"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = prepare_df(sigdict, combined_data, combined_bkg_yield, combined_bkg_error)\n",
    "display(df['VLLD_mu']['M600'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0710dda-bf15-4edd-9177-4f7a1d56778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbin    signal  nObs    nBkg    bkgErr  S/sqrtB deltaB\n",
      "1\t321.20\t147.29\t147.29\t8.73\t26.47\t1.06\n",
      "2\t293.06\t167.20\t167.20\t8.30\t22.66\t1.05\n",
      "3\t264.71\t160.08\t160.08\t8.15\t20.92\t1.05\n",
      "4\t251.88\t155.94\t155.94\t8.85\t20.17\t1.06\n",
      "5\t262.91\t181.57\t181.57\t13.90\t19.51\t1.08\n",
      "6\t157.65\t77.01\t77.01\t6.99\t17.97\t1.09\n",
      "7\t216.73\t150.70\t150.70\t9.26\t17.65\t1.06\n",
      "8\t230.97\t183.81\t183.81\t9.42\t17.04\t1.05\n",
      "9\t215.23\t161.35\t161.35\t7.94\t16.94\t1.05\n",
      "10\t191.01\t146.25\t146.25\t8.29\t15.80\t1.06\n",
      "11\t216.32\t193.24\t193.24\t5.14\t15.56\t1.03\n",
      "12\t187.78\t148.68\t148.68\t13.20\t15.40\t1.09\n",
      "13\t186.95\t152.77\t152.77\t9.56\t15.13\t1.06\n",
      "14\t210.68\t203.79\t203.79\t9.21\t14.76\t1.05\n",
      "15\t148.55\t106.26\t106.26\t6.85\t14.41\t1.06\n",
      "16\t140.88\t142.09\t142.09\t14.00\t11.82\t1.10\n",
      "17\t162.87\t193.77\t193.77\t9.30\t11.70\t1.05\n",
      "18\t106.16\t83.96\t83.96\t5.89\t11.59\t1.07\n",
      "19\t105.30\t167.53\t167.53\t6.74\t8.14\t1.04\n",
      "20\t7.54\t8.16\t8.16\t0.73\t2.64\t1.09\n"
     ]
    }
   ],
   "source": [
    "# Assuming df['VLLD_mu']['M100'] is a DataFrame\n",
    "print(f\"{'nbin':<7} {'signal':<7} {'nObs':<7} {'nBkg':<7} {'bkgErr':<7} {'S/sqrtB':<7} {'deltaB'}\")\n",
    "for index, row in df['VLLD_mu']['M100'].iterrows():\n",
    "    print(f\"{index+1}\\t{row['signal']:.2f}\\t{row['nObs']:.2f}\\t{row['nBkg']:.2f}\\t{row['bkg_err']:.2f}\\t{row['S/sqrtB']:.2f}\\t{row['deltaB']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77a15c-653a-4332-9827-59e1793e3f60",
   "metadata": {},
   "source": [
    "## Writing into text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80fe754-e2e9-4dd4-99b9-406e20477867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funtions loaded.\n"
     ]
    }
   ],
   "source": [
    "def write_df_to_file(df, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        # Write the header with fixed widths\n",
    "        header = f\"{'bin':<10}{'signal':<10}{'nObs':<10}{'nBkg':<10}{'bkg_err':<10}{'S/sqrtB':<10}{'deltaB':<10}\"\n",
    "        f.write(header + '\\n')\n",
    "        \n",
    "        # Write the data rows\n",
    "        for index, row in df.iterrows():\n",
    "            line = f\"{int(row['bin']):<10}\"\n",
    "            line += f\"{float(row['signal']):<10.2f}\"\n",
    "            line += f\"{float(row['nObs']):<10.2f}\"\n",
    "            line += f\"{float(row['nBkg']):<10.2f}\"\n",
    "            line += f\"{float(row['bkg_err']):<10.2f}\"\n",
    "            line += f\"{float(row['S/sqrtB']):<10.2f}\"\n",
    "            line += f\"{float(row['deltaB']):<10.4f}\"\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "def write_datacard(df, datacard):\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    num_bins = len(df)  # Total number of bins\n",
    "    \n",
    "    if num_bins == 0:\n",
    "        print(f'Warning: Zero bins detected! SKipping file {datacard}')\n",
    "        return\n",
    "        \n",
    "    #print(f'Processing {num_bins} bins ')\n",
    "    \n",
    "    with open(datacard, 'w') as f:\n",
    "        #header information\n",
    "        f.write(f\"imax {num_bins}                          # number of channels\\n\")\n",
    "        f.write(f\"jmax 1                           # number of backgrounds\\n\")\n",
    "        f.write(f\"kmax {num_bins}                          # number of nuisance parameters\\n\")\n",
    "        f.write(\"------------\\n\")\n",
    "        \n",
    "        # Bin section\n",
    "        f.write(f\"{'bin':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"bin{i + 1}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "        \n",
    "        # Observation section\n",
    "        f.write(f\"{'observation':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"{int(df['nObs'].iat[i])}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "        f.write(\"------------\\n\")\n",
    "\n",
    "        # Bin-Bin section\n",
    "        f.write(f\"{'bin':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"bin{i + 1}\\tbin{i + 1}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "        \n",
    "        #Process section\n",
    "        f.write(f\"{'process':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += \"sig\\tbkg\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "        #Process ID section:\n",
    "        f.write(f\"{'process':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"{-1*(i + 1)}\\t{(i + 1)}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "        # Rate section\n",
    "        f.write(f\"{'rate':<16}\")\n",
    "        line = \"\"\n",
    "        for i in range(num_bins): line += f\"{df['signal'].at[i]:.2f}\\t{df['nBkg'].at[i]:.2f}\\t\"\n",
    "        line = line[:-1]\n",
    "        f.write(line + \"\\n\")\n",
    "        f.write(\"------------\\n\")\n",
    "\n",
    "        #uncertainty:\n",
    "        for i in range(num_bins):\n",
    "            uncertainty_line = f\"xs{i + 1:<6}lnN\\t\"\n",
    "            values = []\n",
    "            for j in range(num_bins):\n",
    "                if j == i: # Diagonal element\n",
    "                    values.append(\"-\")  # Signal uncertainty\n",
    "                    uncertainty_value = df['deltaB'][i]\n",
    "                    values.append(f\"{uncertainty_value:.5f}\") # Background uncertainty\n",
    "                else:\n",
    "                    values.append(\"-\") # Signal uncertainty\n",
    "                    values.append(\"-\") # Background uncertainty\n",
    "            uncertainty_line += \"\\t\".join(values)\n",
    "            f.write(uncertainty_line + \"\\n\")\n",
    "            \n",
    "    print(f'Wrote file: {datacard}')  \n",
    "    \n",
    "print('Funtions loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "656ae9dc-051e-4780-aff3-c404f036d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote text file: yields/yields_VLLD_ele_M100.txt\n",
      "Wrote text file: yields/yields_VLLD_ele_M200.txt\n",
      "Wrote text file: yields/yields_VLLD_ele_M300.txt\n",
      "Wrote text file: yields/yields_VLLD_ele_M400.txt\n",
      "Wrote text file: yields/yields_VLLD_ele_M600.txt\n",
      "Wrote text file: yields/yields_VLLD_ele_M800.txt\n",
      "Wrote text file: yields/yields_VLLD_ele_M1000.txt\n",
      "Wrote text file: yields/yields_VLLD_mu_M100.txt\n",
      "Wrote text file: yields/yields_VLLD_mu_M200.txt\n",
      "Wrote text file: yields/yields_VLLD_mu_M300.txt\n",
      "Wrote text file: yields/yields_VLLD_mu_M400.txt\n",
      "Wrote text file: yields/yields_VLLD_mu_M600.txt\n",
      "Wrote text file: yields/yields_VLLD_mu_M800.txt\n",
      "\n",
      "Warning: Information for the following samples are not found.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "not_found = []\n",
    "\n",
    "for sample, subs in sigdict.items():\n",
    "    for subsample, val in subs.items():\n",
    "        yieldfile = f\"yields/yields_{sample}_{subsample}.txt\"\n",
    "        os.makedirs('yields', exist_ok=True)\n",
    "        \n",
    "        # Check if the DataFrame for the current sample and subsample exists\n",
    "        if sample in df and subsample in df[sample]:\n",
    "            write_df_to_file(df[sample][subsample], yieldfile)\n",
    "            print(f'Wrote text file: {yieldfile}')\n",
    "        else: not_found.append(f'{sample}_{subsample}')\n",
    "\n",
    "print('\\nWarning: Information for the following samples are not found.')\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742372ce-3001-4469-8ea7-68c9ee1bf192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file: datacards/datacard_VLLD_ele_M100.txt\n",
      "Wrote file: datacards/datacard_VLLD_ele_M200.txt\n",
      "Wrote file: datacards/datacard_VLLD_ele_M300.txt\n",
      "Wrote file: datacards/datacard_VLLD_ele_M400.txt\n",
      "Wrote file: datacards/datacard_VLLD_ele_M600.txt\n",
      "Wrote file: datacards/datacard_VLLD_ele_M800.txt\n",
      "Wrote file: datacards/datacard_VLLD_ele_M1000.txt\n",
      "Wrote file: datacards/datacard_VLLD_mu_M100.txt\n",
      "Wrote file: datacards/datacard_VLLD_mu_M200.txt\n",
      "Wrote file: datacards/datacard_VLLD_mu_M300.txt\n",
      "Wrote file: datacards/datacard_VLLD_mu_M400.txt\n",
      "Wrote file: datacards/datacard_VLLD_mu_M600.txt\n",
      "Wrote file: datacards/datacard_VLLD_mu_M800.txt\n",
      "\n",
      "Warning: Information for the following samples are not found.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "not_found = []\n",
    "\n",
    "for sample, subs in sigdict.items():\n",
    "    for subsample, val in subs.items():\n",
    "        datacard = f\"datacards/datacard_{sample}_{subsample}.txt\"\n",
    "        os.makedirs('datacards', exist_ok=True)\n",
    "\n",
    "        # Check if the DataFrame for the current sample and subsample exists\n",
    "        if sample in df and subsample in df[sample]:\n",
    "            #if not (sample in 'VLLD_mu' and subsample in 'M100') : continue\n",
    "            write_datacard(df[sample][subsample], datacard)\n",
    "            \n",
    "        else: not_found.append(f'{sample}_{subsample}')\n",
    "\n",
    "print('\\nWarning: Information for the following samples are not found.')\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8cf2a-8997-4f2f-b01c-fe5e1f386ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
